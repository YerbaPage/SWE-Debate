#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import glob
import logging
from typing import List, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def is_instance_completed(instance_id: str, max_iterations: int, base_dir: str = "tmp") -> bool:
    """
    åˆ¤æ–­instanceæ˜¯å¦å·²ç»å®Œæˆå¤„ç†
    
    ä¿®æ­£åçš„é€»è¾‘ï¼š
    1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„patchå’Œreportæ–‡ä»¶ï¼ˆpatch_applied=Trueä¸”æœ‰patchå†…å®¹ï¼‰
    2. å¦‚æœæœ‰æˆåŠŸçš„patchï¼Œç›´æ¥è®¤ä¸ºå®Œæˆ
    3. å¦‚æœæ²¡æœ‰æˆåŠŸçš„patchï¼Œå†æ£€æŸ¥æ˜¯å¦è¾¾åˆ°max_iterations
    4. è¾¾åˆ°max_iterationsä½†æ²¡æœ‰finish nodeä¹Ÿç®—å®Œæˆ
    
    Args:
        instance_id: å®ä¾‹ID
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        
    Returns:
        bool: å¦‚æœinstanceå·²ç»å®Œæˆè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    # æŸ¥æ‰¾trajectoryæ–‡ä»¶
    trajectory_files = glob.glob(f"{base_dir}/trajectory/{instance_id}/*_trajectory.json")
    
    if not trajectory_files:
        logger.info(f"No trajectory file found for {instance_id}")
        return False
    
    # ä½¿ç”¨æœ€æ–°çš„trajectoryæ–‡ä»¶
    latest_trajectory = max(trajectory_files)
    
    try:
        with open(latest_trajectory, 'r', encoding='utf-8') as f:
            trajectory_data = json.load(f)
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹
        def find_all_nodes(node_data, nodes_list=None):
            if nodes_list is None:
                nodes_list = []
            if isinstance(node_data, dict):
                nodes_list.append(node_data)
                if "children" in node_data:
                    for child in node_data["children"]:
                        find_all_nodes(child, nodes_list)
            return nodes_list
        
        # ä»rootèŠ‚ç‚¹å¼€å§‹æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹
        all_nodes = []
        if "root" in trajectory_data:
            all_nodes = find_all_nodes(trajectory_data["root"])
        
        # æ­¥éª¤1: ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„patchå’Œreportæ–‡ä»¶
        report_files = glob.glob(f"{base_dir}/experience/{instance_id}/*_report.json")
        
        if report_files:
            # æ£€æŸ¥æœ€æ–°çš„reportæ–‡ä»¶
            latest_report = max(report_files)
            
            try:
                with open(latest_report, 'r', encoding='utf-8') as f:
                    report_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆpatchå¹¶æµ‹è¯•æ‰§è¡Œ
                patch_applied = report_data.get("patch_applied", False)
                patch = report_data.get("patch", "")
                
                if patch_applied and patch:
                    logger.info(f"Instance {instance_id}: Successfully completed with patch applied and tested")
                    return True
                    
            except Exception as e:
                logger.error(f"Error reading report file {latest_report}: {e}")
        
        # æ­¥éª¤2: æ£€æŸ¥æ˜¯å¦è¾¾åˆ°max_iterations
        target_node_id = max_iterations - 1
        target_node = None
        
        for node in all_nodes:
            if node.get("node_id") == target_node_id:
                target_node = node
                break
        
        if target_node:
            # æ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦å®Œæ•´æ‰§è¡Œ
            visits = target_node.get("visits", 0)
            has_observation = False
            
            # æ£€æŸ¥action_stepsä¸­æ˜¯å¦æœ‰è§‚å¯Ÿç»“æœ
            if "action_steps" in target_node:
                for step in target_node["action_steps"]:
                    if step.get("observation") is not None:
                        has_observation = True
                        break
            
            if visits > 0 and has_observation:
                logger.info(f"Instance {instance_id}: Max iterations completed")
                return True
        
        # æ­¥éª¤3: æ£€æŸ¥æ˜¯å¦å› ä¸ºå…¶ä»–åŸå› ï¼ˆå¦‚è¾¾åˆ°max_finished_nodesï¼‰è€Œå®Œæˆ
        # æŸ¥æ‰¾finish nodes
        finish_nodes = []
        for node in all_nodes:
            if "action_steps" in node:
                for step in node["action_steps"]:
                    action = step.get("action", {})
                    if action.get("action_name") == "Finish" or action.get("name") == "Finish":
                        finish_nodes.append(node)
                        break
        
        if finish_nodes:
            logger.info(f"Instance {instance_id}: Found {len(finish_nodes)} finish nodes but no successful patch generated")
            # å¦‚æœæœ‰finish nodesä½†æ²¡æœ‰æˆåŠŸçš„patchï¼Œè®¤ä¸ºæ²¡æœ‰å®Œæˆ
            return False
        
        # æ­¥éª¤4: æ²¡æœ‰finish nodesä¸”æ²¡æœ‰è¾¾åˆ°max_iterationsï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹è¡¨æ˜æœç´¢å·²ç»è¿è¡Œ
        if len(all_nodes) >= max_iterations * 0.8:  # å¦‚æœèŠ‚ç‚¹æ•°è¾¾åˆ°max_iterationsçš„80%ï¼Œå¯èƒ½æ˜¯å› ä¸ºå…¶ä»–åŸå› æå‰ç»ˆæ­¢
            logger.info(f"Instance {instance_id}: Search appears to have run significantly ({len(all_nodes)} nodes) but no completion criteria met")
            return False
        
        logger.info(f"Instance {instance_id}: Search not completed (only {len(all_nodes)} nodes, target: {max_iterations})")
        return False
            
    except Exception as e:
        logger.error(f"Error checking completion status for {instance_id}: {e}")
        return False


def has_trajectory_file(instance_id: str, base_dir: str) -> bool:
    """
    æ£€æŸ¥å®ä¾‹æ˜¯å¦æœ‰trajectoryæ–‡ä»¶ï¼ˆå³å·²å¼€å§‹è¿è¡Œï¼‰
    
    Args:
        instance_id: å®ä¾‹ID
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        
    Returns:
        bool: å¦‚æœæœ‰trajectoryæ–‡ä»¶è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    trajectory_files = glob.glob(f"{base_dir}/trajectory/{instance_id}/*_trajectory.json")
    return len(trajectory_files) > 0


def get_resolved_status(instance_id: str, base_dir: str) -> Tuple[bool, bool]:
    """
    è·å–å®ä¾‹çš„resolvedçŠ¶æ€
    
    Args:
        instance_id: å®ä¾‹ID
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        
    Returns:
        Tuple[has_report, resolved]: (æ˜¯å¦æœ‰æŠ¥å‘Šæ–‡ä»¶, æ˜¯å¦å·²è§£å†³)
    """
    report_files = glob.glob(f"{base_dir}/experience/{instance_id}/*_report.json")
    
    if not report_files:
        return False, False
    
    # ä½¿ç”¨æœ€æ–°çš„reportæ–‡ä»¶
    latest_report = max(report_files)
    
    try:
        with open(latest_report, 'r', encoding='utf-8') as f:
            report_data = json.load(f)
        
        resolved = report_data.get("resolved", False)
        return True, resolved
        
    except Exception as e:
        logger.error(f"Error reading report file {latest_report}: {e}")
        return False, False


def check_completion_status():
    """
    ä½¿ç”¨is_instance_completedå‡½æ•°ç»Ÿè®¡å·²å®Œæˆçš„å®ä¾‹æ•°é‡ï¼Œå¹¶è®¡ç®—æ­£ç¡®ç‡ - LITEç‰ˆæœ¬
    """
    # è®¾ç½®å‚æ•° - ä¸“é—¨é’ˆå¯¹liteæ•°æ®é›†
    base_dir = "/data/swebench/workspace/SWE-Search/tmp/SWE_Search_deepseek0324_lite"#_REACT"
    max_iterations = 20
    instance_list_file = "/data/swebench/workspace/SWE-Search/lite.txt"
    
    # è¯»å–æ‰€æœ‰å®ä¾‹ID
    with open(instance_list_file, 'r', encoding='utf-8') as f:
        instance_ids = [line.strip() for line in f if line.strip()]
    
    print(f"ğŸ“‹ æ€»å…±éœ€è¦æ£€æŸ¥ {len(instance_ids)} ä¸ªå®ä¾‹ (LITEæ•°æ®é›†)")
    print(f"ğŸ“ åŸºç¡€ç›®å½•: {base_dir}")
    print(f"ğŸ”„ æœ€å¤§è¿­ä»£æ•°: {max_iterations}")
    print("-" * 80)
    
    # ç»Ÿè®¡å®ŒæˆçŠ¶æ€å’Œè§£å†³çŠ¶æ€
    completed_instances = []
    incomplete_instances = []
    resolved_instances = []
    completed_but_not_resolved = []
    started_but_incomplete = []  # å·²è¿è¡Œä½†æœªå®Œæˆ
    not_started = []  # æœªå¼€å§‹è¿è¡Œ
    
    for i, instance_id in enumerate(instance_ids, 1):
        try:
            is_completed = is_instance_completed(instance_id, max_iterations, base_dir)
            has_report, resolved = get_resolved_status(instance_id, base_dir)
            has_trajectory = has_trajectory_file(instance_id, base_dir)
            
            if is_completed:
                completed_instances.append(instance_id)
                if resolved:
                    resolved_instances.append(instance_id)
                    status = "âœ… å·²å®Œæˆ (resolved: True)"
                else:
                    completed_but_not_resolved.append(instance_id)
                    status = "âœ… å·²å®Œæˆ (resolved: False)"
            else:
                incomplete_instances.append(instance_id)
                if has_trajectory:
                    started_but_incomplete.append(instance_id)
                    status = "ğŸ”„ å·²è¿è¡Œä½†æœªå®Œæˆ"
                else:
                    not_started.append(instance_id)
                    status = "â­• æœªå¼€å§‹è¿è¡Œ"
            
            print(f"[{i:2d}/{len(instance_ids)}] {instance_id:<25} {status}")
            
        except Exception as e:
            incomplete_instances.append(instance_id)
            not_started.append(instance_id)
            print(f"[{i:2d}/{len(instance_ids)}] {instance_id:<25} âš ï¸ æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    # è®¡ç®—å„ç§ç‡
    completion_rate = len(completed_instances) / len(instance_ids) * 100
    accuracy_rate = len(resolved_instances) / len(instance_ids) * 100
    success_rate_in_completed = len(resolved_instances) / len(completed_instances) * 100 if completed_instances else 0
    started_rate = (len(completed_instances) + len(started_but_incomplete)) / len(instance_ids) * 100
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("-" * 80)
    print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ (LITEæ•°æ®é›†):")
    print(f"   æ€»å®ä¾‹æ•°: {len(instance_ids)}")
    print(f"   å·²å®Œæˆæ•°: {len(completed_instances)}")
    print(f"   å·²è¿è¡Œä½†æœªå®Œæˆæ•°: {len(started_but_incomplete)}")
    print(f"   æœªå¼€å§‹è¿è¡Œæ•°: {len(not_started)}")
    print(f"   å·²è§£å†³æ•° (resolved=True): {len(resolved_instances)}")
    print(f"   å·²å®Œæˆä½†æœªè§£å†³æ•°: {len(completed_but_not_resolved)}")
    print()
    print(f"ğŸ“ˆ ç‡è®¡ç®—:")
    print(f"   å·²å¼€å§‹è¿è¡Œç‡: {started_rate:.1f}% ({len(completed_instances) + len(started_but_incomplete)}/{len(instance_ids)})")
    print(f"   å®Œæˆç‡: {completion_rate:.1f}% ({len(completed_instances)}/{len(instance_ids)})")
    print(f"   æ­£ç¡®ç‡ (æ€»ä½“): {accuracy_rate:.1f}% ({len(resolved_instances)}/{len(instance_ids)})")
    print(f"   æˆåŠŸç‡ (å·²å®Œæˆä¸­): {success_rate_in_completed:.1f}% ({len(resolved_instances)}/{len(completed_instances)})")
    
    if not_started:
        print(f"\nâ­• æœªå¼€å§‹è¿è¡Œçš„å®ä¾‹ ({len(not_started)}ä¸ª):")
        for instance_id in not_started:
            print(f"   - {instance_id}")
    
    if started_but_incomplete:
        print(f"\nğŸ”„ å·²è¿è¡Œä½†æœªå®Œæˆçš„å®ä¾‹ ({len(started_but_incomplete)}ä¸ª):")
        for instance_id in started_but_incomplete:
            print(f"   - {instance_id}")
    
    if completed_but_not_resolved:
        print(f"\nâš ï¸ å·²å®Œæˆä½†æœªè§£å†³çš„å®ä¾‹ ({len(completed_but_not_resolved)}ä¸ª):")
        for instance_id in completed_but_not_resolved:
            print(f"   - {instance_id}")
    
    if resolved_instances:
        print(f"\nğŸ‰ å·²è§£å†³çš„å®ä¾‹ ({len(resolved_instances)}ä¸ª):")
        for instance_id in resolved_instances:
            print(f"   - {instance_id}")
    
    return len(completed_instances), len(incomplete_instances), len(resolved_instances), len(instance_ids), len(started_but_incomplete)

if __name__ == "__main__":
    completed_count, incomplete_count, resolved_count, total_count, started_but_incomplete_count = check_completion_status()
    print(f"\nğŸ æœ€ç»ˆç»“æœ (LITEæ•°æ®é›†):")
    print(f"   æ€»æ•°: {total_count} ä¸ª")
    print(f"   å·²å®Œæˆ: {completed_count} ä¸ª")
    print(f"   å·²è¿è¡Œä½†æœªå®Œæˆ: {started_but_incomplete_count} ä¸ª") 
    print(f"   æœªå¼€å§‹è¿è¡Œ: {total_count - completed_count - started_but_incomplete_count} ä¸ª")
    print(f"   å·²è§£å†³: {resolved_count} ä¸ª")
    if completed_count > 0:
        print(f"   æ­£ç¡®ç‡ (å·²å®Œæˆä¸­): {resolved_count}/{completed_count} = {resolved_count/completed_count*100:.1f}%")
    else:
        print(f"   æ­£ç¡®ç‡ (å·²å®Œæˆä¸­): 0/0 = 0.0%") 